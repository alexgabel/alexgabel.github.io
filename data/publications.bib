
@article{gabel_type-ii_2025,
	title = {Type-{II} neural symmetry detection with {Lie} theory},
	volume = {15},
	copyright = {2025 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-025-17098-8},
	doi = {10.1038/s41598-025-17098-8},
	abstract = {Understanding symmetries within data is crucial for explainability and enhancing model efficiency in artificial intelligence. This work investigates an approach to neural symmetry detection, specifically leveraging the mathematical framework of Lie theory. Our approach projects data into a low-dimensional latent space, where symmetry transformations can be efficiently applied. By leveraging the matrix exponential, we accurately capture both affine and non-affine transformations, allowing for improved data augmentation and model selection as potential applications. Our method also estimates transformation magnitude distributions, providing deeper insights into the geometric structure of data. Experiments conducted on augmented MNIST demonstrate the effectiveness of our approach in detecting complex symmetries with multiple transformations. This work paves the way for more interpretable and parameter efficient AI models by identifying structural priors that align with the inherent symmetries in data.},
	language = {en},
	number = {1},
	urldate = {2025-11-05},
	journal = {Scientific Reports},
	author = {Gabel, Alex and Quax, Rick and Gavves, Efstratios},
	month = sep,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Mathematics and computing},
	pages = {33500},
	file = {Full Text PDF:/Users/agabel/Zotero/storage/VGBGJMTG/Gabel et al. - 2025 - Type-II neural symmetry detection with Lie theory.pdf:application/pdf},
}

@article{gabel_data-driven_2024,
	title = {Data-driven {Lie} point symmetry detection for continuous dynamical systems},
	volume = {5},
	issn = {2632-2153},
	url = {https://doi.org/10.1088/2632-2153/ad2629},
	doi = {10.1088/2632-2153/ad2629},
	abstract = {Symmetry detection, the task of discovering the underlying symmetries of a given dataset, has been gaining popularity in the machine learning community, particularly in science and engineering applications. Most previous works focus on detecting ‘canonical’ symmetries such as translation, scaling, and rotation, and cast the task as a modeling problem involving complex inductive biases and architecture design of neural networks. We challenge these assumptions and propose that instead of constructing biases, we can learn to detect symmetries from raw data without prior knowledge. The approach presented in this paper provides a flexible way to scale up the detection procedure to non-canonical symmetries, and has the potential to detect both known and unknown symmetries alike. Concretely, we focus on predicting the generators of Lie point symmetries of partial differential equations, more specifically, evolutionary equations for ease of data generation. Our results demonstrate that well-established neural network architectures are capable of recognizing symmetry generators, even in unseen dynamical systems. These findings have the potential to make non-canonical symmetries more accessible to applications, including model selection, sparse identification, and data interpretability.},
	language = {en},
	number = {1},
	urldate = {2025-11-05},
	journal = {Machine Learning: Science and Technology},
	author = {Gabel, Alex and Quax, Rick and Gavves, Efstratios},
	month = mar,
	year = {2024},
	note = {Publisher: IOP Publishing},
	pages = {015037},
	file = {IOP Full Text PDF:/Users/agabel/Zotero/storage/XBMWFECZ/Gabel et al. - 2024 - Data-driven Lie point symmetry detection for continuous dynamical systems.pdf:application/pdf},
}

@inproceedings{gabel_learning_2023,
	title = {Learning {Lie} {Group} {Symmetry} {Transformations} with {Neural} {Networks}},
	url = {https://proceedings.mlr.press/v221/gabel23a.html},
	abstract = {The problem of detecting and quantifying the presence of symmetries in datasets is useful for model selection, generative modeling, and data analysis, amongst others. While existing methods for hard-coding transformations in neural networks require prior knowledge of the symmetries of the task at hand, this work focuses on discovering and characterising unknown symmetries present in the dataset, namely, Lie group symmetry transformations beyond the traditional ones usually considered in the field (rotation, scaling, and translation). Specifically, we consider a scenario in which a dataset has been transformed by a one-parameter subgroup of transformations with different parameter values for each data point. Our goal is to characterise the transformation group and the distribution of the parameter values, even when they aren’t small or the transformation group isn’t one of the traditional ones. The results showcase the effectiveness of the approach in both these settings.},
	language = {en},
	urldate = {2025-11-05},
	booktitle = {Proceedings of 2nd {Annual} {Workshop} on {Topology}, {Algebra}, and {Geometry} in {Machine} {Learning} ({TAG}-{ML})},
	publisher = {PMLR},
	author = {Gabel, Alex and Klein, Victoria and Valperga, Riccardo and Lamb, Jeroen S. W. and Webster, Kevin and Quax, Rick and Gavves, Efstratios},
	month = sep,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {50--59},
	file = {Full Text PDF:/Users/agabel/Zotero/storage/KAV22GNN/Gabel et al. - 2023 - Learning Lie Group Symmetry Transformations with Neural Networks.pdf:application/pdf},
}
